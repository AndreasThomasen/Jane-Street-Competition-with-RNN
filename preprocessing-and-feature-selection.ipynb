{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and feature selection of the Jane Street Market Prediction Competition Data\n",
    "\n",
    "In machine learning applications preprocessing of data and feature reduction is extremely important. Firstly it allows models to run on data with much lower dimension. This enables them to train faster and may even reduce randomness in the data, which makes predictions hard. Additionally, much of the raw data provided in real world scenarios have imperfections such as missing entries or NaN, etc.\n",
    "\n",
    "We here go into some detail with the training set provided by Jane Street in their Market Prediction Competition. This notebook can be summarized as follows.\n",
    "* We will first look at the data to determine which features are heavily correlated so that we can reduce the dimensionality of the data.\n",
    "* We discuss some of the results and possible strategies\n",
    "* We then reduce the feature space by PCA\n",
    "* Finally we try to train a very simply neural network to predict trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the training data. This will take a while, so make yourself comfortable meanwhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0          1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1         -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2         -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3         -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4          1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "\n",
       "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0     8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2     9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3     0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4     4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "\n",
       "   feature_128  feature_129  ts_id  \n",
       "0     2.301488    11.445807      0  \n",
       "1    -1.304614     1.898684      1  \n",
       "2     6.638248     9.427299      2  \n",
       "3     3.856384     1.013469      3  \n",
       "4     0.362636     3.926633      4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if there are any NaN or similar entries in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['feature_'+str(i) for i in range(130)]\n",
    "train_features = train[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_0      False\n",
       "feature_1      False\n",
       "feature_2      False\n",
       "feature_3       True\n",
       "feature_4       True\n",
       "               ...  \n",
       "feature_125     True\n",
       "feature_126     True\n",
       "feature_127     True\n",
       "feature_128     True\n",
       "feature_129     True\n",
       "Length: 130, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems at least some of the features have some invalid or missing entries. We have to find a way to deal with this. Let's examine the datatypes as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_0        int64\n",
       "feature_1      float64\n",
       "feature_2      float64\n",
       "feature_3      float64\n",
       "feature_4      float64\n",
       "                ...   \n",
       "feature_125    float64\n",
       "feature_126    float64\n",
       "feature_127    float64\n",
       "feature_128    float64\n",
       "feature_129    float64\n",
       "Length: 130, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_0 is int64, which we knew, but I wonder if there are more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0\n",
       "0          1\n",
       "1         -1\n",
       "2         -1\n",
       "3         -1\n",
       "4          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_int_features = train_features.loc[:,lambda df: df.dtypes == 'int64']\n",
    "train_int_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.323046</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.989982</td>\n",
       "      <td>-1.055090</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.193794</td>\n",
       "      <td>0.138212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.151877</td>\n",
       "      <td>-0.384952</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>0.806463</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>-0.614188</td>\n",
       "      <td>-0.354800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.448261</td>\n",
       "      <td>2.668029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>0.066872</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>-1.006373</td>\n",
       "      <td>-0.676458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.508206</td>\n",
       "      <td>2.484260</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>-0.161518</td>\n",
       "      <td>-0.128149</td>\n",
       "      <td>-0.195006</td>\n",
       "      <td>-0.143780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.683018</td>\n",
       "      <td>1.450991</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -1.872746  -2.191242  -0.474163  -0.323046   0.014688  -0.002484   \n",
       "1  -1.349537  -1.704709   0.068058   0.028432   0.193794   0.138212   \n",
       "2   0.812780  -0.256156   0.806463   0.400221  -0.614188  -0.354800   \n",
       "3   1.174378   0.344640   0.066872   0.009357  -1.006373  -0.676458   \n",
       "4  -3.172026  -3.093182  -0.161518  -0.128149  -0.195006  -0.143780   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_120  feature_121  \\\n",
       "0        NaN        NaN  -0.989982   -1.055090  ...          NaN          NaN   \n",
       "1        NaN        NaN  -0.151877   -0.384952  ...          NaN          NaN   \n",
       "2        NaN        NaN   5.448261    2.668029  ...          NaN          NaN   \n",
       "3        NaN        NaN   4.508206    2.484260  ...          NaN          NaN   \n",
       "4        NaN        NaN   2.683018    1.450991  ...          NaN          NaN   \n",
       "\n",
       "   feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
       "0     1.168391     8.313583     1.782433    14.018213     2.653056   \n",
       "1    -1.178850     1.777472    -0.915458     2.831612    -1.417010   \n",
       "2     6.115747     9.667908     5.542871    11.671595     7.281757   \n",
       "3     2.838853     0.499251     3.033732     1.513488     4.397532   \n",
       "4     0.344850     4.101145     0.614252     6.623456     0.800129   \n",
       "\n",
       "   feature_127  feature_128  feature_129  \n",
       "0    12.600292     2.301488    11.445807  \n",
       "1     2.297459    -1.304614     1.898684  \n",
       "2    10.060014     6.638248     9.427299  \n",
       "3     1.266037     3.856384     1.013469  \n",
       "4     5.233243     0.362636     3.926633  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_float_features = train_features.loc[:,lambda df: df.dtypes == 'float64']\n",
    "train_float_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot some correlations of a reduced data-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very clear that the data is highly correlated. There are several blocks that could probably be collapsed into one-another. In order to deal with this we have will use T-SNE feature reduction method. Feature_0 looks special since it is integer and either 1 or -1. Let's examine its correlation with the feature 17 - 26 block more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It again seems highly correlated with these features. It could be a feasible strategy to remove this feature entirely, or perhaps incorporate it using the embedding class of torch.nn while removing all of the other features above. Alternatively one could systematically remove features according to how well they correlate with feature_0 or something similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data\n",
    "We will start by scaling the data using standard methods. Firstly we impute the data, i.e. remove missing values such as NaN and replace them with some numerical value that is compatible with our later processing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_val=train_float_features.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace missing values by the mean of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train_float_features.fillna(fill_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of data, so feature reduction using PCA seems like a good first step. We will reduce the number of features to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = 50\n",
    "sc = StandardScaler().fit(train_imputed.to_numpy())\n",
    "features_scaled = sc.transform(train_imputed.to_numpy())\n",
    "pca = PCA(n_components = pca_components).fit(features_scaled)\n",
    "features_pca=pca.transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-60.724236043976504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.score(features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a very simple model at first using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")\n",
    "\n",
    "e_size = 256\n",
    "fc_input = pca_components\n",
    "h_dims = [512,1024]\n",
    "dropout_rate = 0.5\n",
    "output_dropout_rate = 0.2\n",
    "epochs = 1000\n",
    "minibatch_size = 100000\n",
    "\n",
    "class MarketPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarketPredictor, self).__init__()\n",
    "        \n",
    "        self.e = nn.Embedding(2,e_size)\n",
    "        self.deep = nn.Sequential(\n",
    "            nn.Linear(fc_input,h_dims[0]),\n",
    "            nn.BatchNorm1d(h_dims[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(h_dims[0],h_dims[1]),\n",
    "            nn.BatchNorm1d(h_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(h_dims[1],e_size),\n",
    "            nn.BatchNorm1d(e_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "            )\n",
    "        self.reduce = nn.utils.weight_norm(nn.Linear(e_size,1))\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.outdo = nn.Dropout(output_dropout_rate)\n",
    "        \n",
    "    def forward(self,xi,xf):\n",
    "        e_out = self.e(xi)\n",
    "        f_out = self.deep(xf)\n",
    "        ef_out = self.reduce(e_out+f_out)\n",
    "        sig_out = self.outdo(self.sig(ef_out))\n",
    "        \n",
    "        return sig_out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train it. Let's define the loss function first. In the competition we're told that the return on day $i$ is\n",
    "\\begin{equation}\n",
    "p_i = \\sum_j (\\mathit{weight}_{ij}*\\mathit{resp}_{ij}*\\mathit{action}_{ij})\n",
    "\\end{equation}\n",
    "The way we've made the network it gives a sigmoidal output $s_{ij} \\in[0;1]$. Let's make the cost-function\n",
    "\\begin{equation}\n",
    "C = \\sum_i c_i = -\\sum_{i,j} (\\mathit{weight}_{ij}*\\mathit{resp}_{ij}*s_{ij}).\n",
    "\\end{equation}\n",
    "This has the same minimum as $p_i$, but the advantage is that it's got finite gradients with respect to the model parameters, and so should work better with SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(s,wr):\n",
    "    return - torch.dot(s,wr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some torch tensors which hold the training data and apply our model to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrtensor = torch.tensor(train.loc[:,['weight','resp']].to_numpy(),dtype=torch.float)\n",
    "wrtensor = torch.mul(wrtensor[:,0],wrtensor[:,1]).to(dev)\n",
    "itensor = torch.tensor(((train.loc[:,'feature_0']+1)//2).to_numpy(),dtype=torch.long,device=dev)\n",
    "ftensor = torch.tensor(features_pca,dtype=torch.float,device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MarketPredictor().to(dev)\n",
    "opt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0 / 1000\n",
      "Loss is 60.0166015625\n",
      "Epoch is 1 / 1000\n",
      "Loss is -3.4017839431762695\n",
      "Epoch is 2 / 1000\n",
      "Loss is -18.198341369628906\n",
      "Epoch is 3 / 1000\n",
      "Loss is -52.713897705078125\n",
      "Epoch is 4 / 1000\n",
      "Loss is -25.209484100341797\n",
      "Epoch is 5 / 1000\n",
      "Loss is -45.9842643737793\n",
      "Epoch is 6 / 1000\n",
      "Loss is -52.66785430908203\n",
      "Epoch is 7 / 1000\n",
      "Loss is -14.685450553894043\n",
      "Epoch is 8 / 1000\n",
      "Loss is -35.70700454711914\n",
      "Epoch is 9 / 1000\n",
      "Loss is -6.861891746520996\n",
      "Epoch is 10 / 1000\n",
      "Loss is -4.207523345947266\n",
      "Epoch is 11 / 1000\n",
      "Loss is -67.50947570800781\n",
      "Epoch is 12 / 1000\n",
      "Loss is -74.55643463134766\n",
      "Epoch is 13 / 1000\n",
      "Loss is -21.215484619140625\n",
      "Epoch is 14 / 1000\n",
      "Loss is -102.4227294921875\n",
      "Epoch is 15 / 1000\n",
      "Loss is -94.12017822265625\n",
      "Epoch is 16 / 1000\n",
      "Loss is -53.854942321777344\n",
      "Epoch is 17 / 1000\n",
      "Loss is -59.80472183227539\n",
      "Epoch is 18 / 1000\n",
      "Loss is -54.56261444091797\n",
      "Epoch is 19 / 1000\n",
      "Loss is -51.64927673339844\n",
      "Epoch is 20 / 1000\n",
      "Loss is -52.47942352294922\n",
      "Epoch is 21 / 1000\n",
      "Loss is -81.7311019897461\n",
      "Epoch is 22 / 1000\n",
      "Loss is -91.425048828125\n",
      "Epoch is 23 / 1000\n",
      "Loss is -59.1328010559082\n",
      "Epoch is 24 / 1000\n",
      "Loss is -107.30055236816406\n",
      "Epoch is 25 / 1000\n",
      "Loss is -80.35708618164062\n",
      "Epoch is 26 / 1000\n",
      "Loss is -74.55162048339844\n",
      "Epoch is 27 / 1000\n",
      "Loss is -73.8118896484375\n",
      "Epoch is 28 / 1000\n",
      "Loss is -69.40159606933594\n",
      "Epoch is 29 / 1000\n",
      "Loss is -50.57126998901367\n",
      "Epoch is 30 / 1000\n",
      "Loss is -101.67044067382812\n",
      "Epoch is 31 / 1000\n",
      "Loss is -75.13169860839844\n",
      "Epoch is 32 / 1000\n",
      "Loss is -82.19342041015625\n",
      "Epoch is 33 / 1000\n",
      "Loss is -46.164581298828125\n",
      "Epoch is 34 / 1000\n",
      "Loss is -70.43367004394531\n",
      "Epoch is 35 / 1000\n",
      "Loss is -69.43693542480469\n",
      "Epoch is 36 / 1000\n",
      "Loss is -99.10262298583984\n",
      "Epoch is 37 / 1000\n",
      "Loss is -66.60710906982422\n",
      "Epoch is 38 / 1000\n",
      "Loss is -64.52003479003906\n",
      "Epoch is 39 / 1000\n",
      "Loss is -101.42455291748047\n",
      "Epoch is 40 / 1000\n",
      "Loss is -98.56932830810547\n",
      "Epoch is 41 / 1000\n",
      "Loss is -90.911376953125\n",
      "Epoch is 42 / 1000\n",
      "Loss is -105.077880859375\n",
      "Epoch is 43 / 1000\n",
      "Loss is -106.99917602539062\n",
      "Epoch is 44 / 1000\n",
      "Loss is -72.69799041748047\n",
      "Epoch is 45 / 1000\n",
      "Loss is -93.51786804199219\n",
      "Epoch is 46 / 1000\n",
      "Loss is -95.00617980957031\n",
      "Epoch is 47 / 1000\n",
      "Loss is -99.07244873046875\n",
      "Epoch is 48 / 1000\n",
      "Loss is -109.58160400390625\n",
      "Epoch is 49 / 1000\n",
      "Loss is -103.62814331054688\n",
      "Epoch is 50 / 1000\n",
      "Loss is -103.40217590332031\n",
      "Epoch is 51 / 1000\n",
      "Loss is -90.63267517089844\n",
      "Epoch is 52 / 1000\n",
      "Loss is -74.72186279296875\n",
      "Epoch is 53 / 1000\n",
      "Loss is -81.82255554199219\n",
      "Epoch is 54 / 1000\n",
      "Loss is -45.5830192565918\n",
      "Epoch is 55 / 1000\n",
      "Loss is -118.41346740722656\n",
      "Epoch is 56 / 1000\n",
      "Loss is -104.33179473876953\n",
      "Epoch is 57 / 1000\n",
      "Loss is -92.51472473144531\n",
      "Epoch is 58 / 1000\n",
      "Loss is -128.2180633544922\n",
      "Epoch is 59 / 1000\n",
      "Loss is -139.0204315185547\n",
      "Epoch is 60 / 1000\n",
      "Loss is -51.496299743652344\n",
      "Epoch is 61 / 1000\n",
      "Loss is -96.62425231933594\n",
      "Epoch is 62 / 1000\n",
      "Loss is -85.27828979492188\n",
      "Epoch is 63 / 1000\n",
      "Loss is -100.64546203613281\n",
      "Epoch is 64 / 1000\n",
      "Loss is -90.81497955322266\n",
      "Epoch is 65 / 1000\n",
      "Loss is -88.69256591796875\n",
      "Epoch is 66 / 1000\n",
      "Loss is -84.32441711425781\n",
      "Epoch is 67 / 1000\n",
      "Loss is -101.32096099853516\n",
      "Epoch is 68 / 1000\n",
      "Loss is -86.42402648925781\n",
      "Epoch is 69 / 1000\n",
      "Loss is -101.05311584472656\n",
      "Epoch is 70 / 1000\n",
      "Loss is -124.55165100097656\n",
      "Epoch is 71 / 1000\n",
      "Loss is -84.17597961425781\n",
      "Epoch is 72 / 1000\n",
      "Loss is -83.46833801269531\n",
      "Epoch is 73 / 1000\n",
      "Loss is -134.60601806640625\n",
      "Epoch is 74 / 1000\n",
      "Loss is -63.085784912109375\n",
      "Epoch is 75 / 1000\n",
      "Loss is -102.73664093017578\n",
      "Epoch is 76 / 1000\n",
      "Loss is -95.01631164550781\n",
      "Epoch is 77 / 1000\n",
      "Loss is -108.7098388671875\n",
      "Epoch is 78 / 1000\n",
      "Loss is -75.87142181396484\n",
      "Epoch is 79 / 1000\n",
      "Loss is -132.69287109375\n",
      "Epoch is 80 / 1000\n",
      "Loss is -96.047119140625\n",
      "Epoch is 81 / 1000\n",
      "Loss is -112.76722717285156\n",
      "Epoch is 82 / 1000\n",
      "Loss is -99.55802917480469\n",
      "Epoch is 83 / 1000\n",
      "Loss is -74.35745239257812\n",
      "Epoch is 84 / 1000\n",
      "Loss is -117.94371795654297\n",
      "Epoch is 85 / 1000\n",
      "Loss is -87.897705078125\n",
      "Epoch is 86 / 1000\n",
      "Loss is -126.42005157470703\n",
      "Epoch is 87 / 1000\n",
      "Loss is -116.51148986816406\n",
      "Epoch is 88 / 1000\n",
      "Loss is -110.00665283203125\n",
      "Epoch is 89 / 1000\n",
      "Loss is -128.79318237304688\n",
      "Epoch is 90 / 1000\n",
      "Loss is -77.78701782226562\n",
      "Epoch is 91 / 1000\n",
      "Loss is -155.48304748535156\n",
      "Epoch is 92 / 1000\n",
      "Loss is -68.95258331298828\n",
      "Epoch is 93 / 1000\n",
      "Loss is -90.08326721191406\n",
      "Epoch is 94 / 1000\n",
      "Loss is -87.56346893310547\n",
      "Epoch is 95 / 1000\n",
      "Loss is -129.01907348632812\n",
      "Epoch is 96 / 1000\n",
      "Loss is -111.78507995605469\n",
      "Epoch is 97 / 1000\n",
      "Loss is -91.76903533935547\n",
      "Epoch is 98 / 1000\n",
      "Loss is -77.76111602783203\n",
      "Epoch is 99 / 1000\n",
      "Loss is -146.52957153320312\n",
      "Epoch is 100 / 1000\n",
      "Loss is -139.94921875\n",
      "Epoch is 101 / 1000\n",
      "Loss is -115.44725036621094\n",
      "Epoch is 102 / 1000\n",
      "Loss is -103.77471923828125\n",
      "Epoch is 103 / 1000\n",
      "Loss is -115.56082153320312\n",
      "Epoch is 104 / 1000\n",
      "Loss is -136.04330444335938\n",
      "Epoch is 105 / 1000\n",
      "Loss is -140.12294006347656\n",
      "Epoch is 106 / 1000\n",
      "Loss is -63.74444580078125\n",
      "Epoch is 107 / 1000\n",
      "Loss is -104.67039489746094\n",
      "Epoch is 108 / 1000\n",
      "Loss is -72.15496826171875\n",
      "Epoch is 109 / 1000\n",
      "Loss is -129.71502685546875\n",
      "Epoch is 110 / 1000\n",
      "Loss is -83.57875061035156\n",
      "Epoch is 111 / 1000\n",
      "Loss is -123.93383026123047\n",
      "Epoch is 112 / 1000\n",
      "Loss is -170.69744873046875\n",
      "Epoch is 113 / 1000\n",
      "Loss is -111.97187805175781\n",
      "Epoch is 114 / 1000\n",
      "Loss is -86.22188568115234\n",
      "Epoch is 115 / 1000\n",
      "Loss is -93.56573486328125\n",
      "Epoch is 116 / 1000\n",
      "Loss is -72.46514129638672\n",
      "Epoch is 117 / 1000\n",
      "Loss is -99.56952667236328\n",
      "Epoch is 118 / 1000\n",
      "Loss is -122.52360534667969\n",
      "Epoch is 119 / 1000\n",
      "Loss is -122.10812377929688\n",
      "Epoch is 120 / 1000\n",
      "Loss is -116.2802963256836\n",
      "Epoch is 121 / 1000\n",
      "Loss is -100.19175720214844\n",
      "Epoch is 122 / 1000\n",
      "Loss is -129.92825317382812\n",
      "Epoch is 123 / 1000\n",
      "Loss is -110.96760559082031\n",
      "Epoch is 124 / 1000\n",
      "Loss is -119.06287384033203\n",
      "Epoch is 125 / 1000\n",
      "Loss is -148.59591674804688\n",
      "Epoch is 126 / 1000\n",
      "Loss is -140.2002410888672\n",
      "Epoch is 127 / 1000\n",
      "Loss is -98.96967315673828\n",
      "Epoch is 128 / 1000\n",
      "Loss is -103.57860565185547\n",
      "Epoch is 129 / 1000\n",
      "Loss is -107.2076644897461\n",
      "Epoch is 130 / 1000\n",
      "Loss is -149.8115234375\n",
      "Epoch is 131 / 1000\n",
      "Loss is -84.8780746459961\n",
      "Epoch is 132 / 1000\n",
      "Loss is -109.92900085449219\n",
      "Epoch is 133 / 1000\n",
      "Loss is -46.4742431640625\n",
      "Epoch is 134 / 1000\n",
      "Loss is -87.66258239746094\n",
      "Epoch is 135 / 1000\n",
      "Loss is -124.32279968261719\n",
      "Epoch is 136 / 1000\n",
      "Loss is -150.74966430664062\n",
      "Epoch is 137 / 1000\n",
      "Loss is -170.29066467285156\n",
      "Epoch is 138 / 1000\n",
      "Loss is -106.51069641113281\n",
      "Epoch is 139 / 1000\n",
      "Loss is -102.9160385131836\n",
      "Epoch is 140 / 1000\n",
      "Loss is -120.30543518066406\n",
      "Epoch is 141 / 1000\n",
      "Loss is -92.23664855957031\n",
      "Epoch is 142 / 1000\n",
      "Loss is -125.73493957519531\n",
      "Epoch is 143 / 1000\n",
      "Loss is -100.10382080078125\n",
      "Epoch is 144 / 1000\n",
      "Loss is -165.58877563476562\n",
      "Epoch is 145 / 1000\n",
      "Loss is -93.80183410644531\n",
      "Epoch is 146 / 1000\n",
      "Loss is -112.61671447753906\n",
      "Epoch is 147 / 1000\n",
      "Loss is -120.5473403930664\n",
      "Epoch is 148 / 1000\n",
      "Loss is -96.91529083251953\n",
      "Epoch is 149 / 1000\n",
      "Loss is -103.84149932861328\n",
      "Epoch is 150 / 1000\n",
      "Loss is -119.00686645507812\n",
      "Epoch is 151 / 1000\n",
      "Loss is -86.94548034667969\n",
      "Epoch is 152 / 1000\n",
      "Loss is -107.78506469726562\n",
      "Epoch is 153 / 1000\n",
      "Loss is -123.7946548461914\n",
      "Epoch is 154 / 1000\n",
      "Loss is -121.35655212402344\n",
      "Epoch is 155 / 1000\n",
      "Loss is -78.25082397460938\n",
      "Epoch is 156 / 1000\n",
      "Loss is -119.05683898925781\n",
      "Epoch is 157 / 1000\n",
      "Loss is -94.02662658691406\n",
      "Epoch is 158 / 1000\n",
      "Loss is -110.92213439941406\n",
      "Epoch is 159 / 1000\n",
      "Loss is -122.32415771484375\n",
      "Epoch is 160 / 1000\n",
      "Loss is -141.24832153320312\n",
      "Epoch is 161 / 1000\n",
      "Loss is -99.92506408691406\n",
      "Epoch is 162 / 1000\n",
      "Loss is -90.42633056640625\n",
      "Epoch is 163 / 1000\n",
      "Loss is -119.46102905273438\n",
      "Epoch is 164 / 1000\n",
      "Loss is -131.63528442382812\n",
      "Epoch is 165 / 1000\n",
      "Loss is -116.58914184570312\n",
      "Epoch is 166 / 1000\n",
      "Loss is -160.39126586914062\n",
      "Epoch is 167 / 1000\n",
      "Loss is -126.8509750366211\n",
      "Epoch is 168 / 1000\n",
      "Loss is -101.32974243164062\n",
      "Epoch is 169 / 1000\n",
      "Loss is -111.84890747070312\n",
      "Epoch is 170 / 1000\n",
      "Loss is -70.57911682128906\n",
      "Epoch is 171 / 1000\n",
      "Loss is -152.90045166015625\n",
      "Epoch is 172 / 1000\n",
      "Loss is -99.01490783691406\n",
      "Epoch is 173 / 1000\n",
      "Loss is -159.21665954589844\n",
      "Epoch is 174 / 1000\n",
      "Loss is -96.81036376953125\n",
      "Epoch is 175 / 1000\n",
      "Loss is -95.01582336425781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 176 / 1000\n",
      "Loss is -127.81610107421875\n",
      "Epoch is 177 / 1000\n",
      "Loss is -112.93250274658203\n",
      "Epoch is 178 / 1000\n",
      "Loss is -132.24606323242188\n",
      "Epoch is 179 / 1000\n",
      "Loss is -125.45437622070312\n",
      "Epoch is 180 / 1000\n",
      "Loss is -140.86886596679688\n",
      "Epoch is 181 / 1000\n",
      "Loss is -95.02462005615234\n",
      "Epoch is 182 / 1000\n",
      "Loss is -86.39507293701172\n",
      "Epoch is 183 / 1000\n",
      "Loss is -131.26588439941406\n",
      "Epoch is 184 / 1000\n",
      "Loss is -101.43397521972656\n",
      "Epoch is 185 / 1000\n",
      "Loss is -140.4254608154297\n",
      "Epoch is 186 / 1000\n",
      "Loss is -117.58477020263672\n",
      "Epoch is 187 / 1000\n",
      "Loss is -118.38843536376953\n",
      "Epoch is 188 / 1000\n",
      "Loss is -142.90771484375\n",
      "Epoch is 189 / 1000\n",
      "Loss is -107.49747467041016\n",
      "Epoch is 190 / 1000\n",
      "Loss is -56.52427673339844\n",
      "Epoch is 191 / 1000\n",
      "Loss is -122.52754211425781\n",
      "Epoch is 192 / 1000\n",
      "Loss is -97.05821990966797\n",
      "Epoch is 193 / 1000\n",
      "Loss is -124.44989776611328\n",
      "Epoch is 194 / 1000\n",
      "Loss is -132.20614624023438\n",
      "Epoch is 195 / 1000\n",
      "Loss is -142.6052703857422\n",
      "Epoch is 196 / 1000\n",
      "Loss is -132.19944763183594\n",
      "Epoch is 197 / 1000\n",
      "Loss is -123.93891143798828\n",
      "Epoch is 198 / 1000\n",
      "Loss is -113.15032196044922\n",
      "Epoch is 199 / 1000\n",
      "Loss is -165.82699584960938\n",
      "Epoch is 200 / 1000\n",
      "Loss is -105.59539794921875\n",
      "Epoch is 201 / 1000\n",
      "Loss is -151.13983154296875\n",
      "Epoch is 202 / 1000\n",
      "Loss is -135.09274291992188\n",
      "Epoch is 203 / 1000\n",
      "Loss is -110.24429321289062\n",
      "Epoch is 204 / 1000\n",
      "Loss is -156.70123291015625\n",
      "Epoch is 205 / 1000\n",
      "Loss is -89.31147003173828\n",
      "Epoch is 206 / 1000\n",
      "Loss is -111.57923889160156\n",
      "Epoch is 207 / 1000\n",
      "Loss is -108.67581176757812\n",
      "Epoch is 208 / 1000\n",
      "Loss is -116.80321502685547\n",
      "Epoch is 209 / 1000\n",
      "Loss is -105.4144287109375\n",
      "Epoch is 210 / 1000\n",
      "Loss is -126.2986068725586\n",
      "Epoch is 211 / 1000\n",
      "Loss is -171.5500030517578\n",
      "Epoch is 212 / 1000\n",
      "Loss is -144.22171020507812\n",
      "Epoch is 213 / 1000\n",
      "Loss is -123.88101959228516\n",
      "Epoch is 214 / 1000\n",
      "Loss is -143.30360412597656\n",
      "Epoch is 215 / 1000\n",
      "Loss is -177.33184814453125\n",
      "Epoch is 216 / 1000\n",
      "Loss is -113.56863403320312\n",
      "Epoch is 217 / 1000\n",
      "Loss is -124.81311798095703\n",
      "Epoch is 218 / 1000\n",
      "Loss is -124.67221069335938\n",
      "Epoch is 219 / 1000\n",
      "Loss is -134.1422119140625\n",
      "Epoch is 220 / 1000\n",
      "Loss is -153.175537109375\n",
      "Epoch is 221 / 1000\n",
      "Loss is -112.49954223632812\n",
      "Epoch is 222 / 1000\n",
      "Loss is -144.1379852294922\n",
      "Epoch is 223 / 1000\n",
      "Loss is -161.68069458007812\n",
      "Epoch is 224 / 1000\n",
      "Loss is -119.66702270507812\n",
      "Epoch is 225 / 1000\n",
      "Loss is -105.5394287109375\n",
      "Epoch is 226 / 1000\n",
      "Loss is -138.20330810546875\n",
      "Epoch is 227 / 1000\n",
      "Loss is -104.10343933105469\n",
      "Epoch is 228 / 1000\n",
      "Loss is -140.12362670898438\n",
      "Epoch is 229 / 1000\n",
      "Loss is -138.54022216796875\n",
      "Epoch is 230 / 1000\n",
      "Loss is -110.25375366210938\n",
      "Epoch is 231 / 1000\n",
      "Loss is -87.48785400390625\n",
      "Epoch is 232 / 1000\n",
      "Loss is -152.2879638671875\n",
      "Epoch is 233 / 1000\n",
      "Loss is -117.3673324584961\n",
      "Epoch is 234 / 1000\n",
      "Loss is -168.847412109375\n",
      "Epoch is 235 / 1000\n",
      "Loss is -113.77413940429688\n",
      "Epoch is 236 / 1000\n",
      "Loss is -131.09686279296875\n",
      "Epoch is 237 / 1000\n",
      "Loss is -170.34083557128906\n",
      "Epoch is 238 / 1000\n",
      "Loss is -110.5871810913086\n",
      "Epoch is 239 / 1000\n",
      "Loss is -128.31369018554688\n",
      "Epoch is 240 / 1000\n",
      "Loss is -144.71817016601562\n",
      "Epoch is 241 / 1000\n",
      "Loss is -130.470458984375\n",
      "Epoch is 242 / 1000\n",
      "Loss is -77.4288101196289\n",
      "Epoch is 243 / 1000\n",
      "Loss is -87.33585357666016\n",
      "Epoch is 244 / 1000\n",
      "Loss is -157.60073852539062\n",
      "Epoch is 245 / 1000\n",
      "Loss is -153.8720703125\n",
      "Epoch is 246 / 1000\n",
      "Loss is -112.1039047241211\n",
      "Epoch is 247 / 1000\n",
      "Loss is -125.85889434814453\n",
      "Epoch is 248 / 1000\n",
      "Loss is -130.93704223632812\n",
      "Epoch is 249 / 1000\n",
      "Loss is -126.9142074584961\n",
      "Epoch is 250 / 1000\n",
      "Loss is -115.81304931640625\n",
      "Epoch is 251 / 1000\n",
      "Loss is -108.88866424560547\n",
      "Epoch is 252 / 1000\n",
      "Loss is -119.32862854003906\n",
      "Epoch is 253 / 1000\n",
      "Loss is -115.08392333984375\n",
      "Epoch is 254 / 1000\n",
      "Loss is -113.07583618164062\n",
      "Epoch is 255 / 1000\n",
      "Loss is -137.4399871826172\n",
      "Epoch is 256 / 1000\n",
      "Loss is -80.91654968261719\n",
      "Epoch is 257 / 1000\n",
      "Loss is -112.2073974609375\n",
      "Epoch is 258 / 1000\n",
      "Loss is -126.11514282226562\n",
      "Epoch is 259 / 1000\n",
      "Loss is -153.89120483398438\n",
      "Epoch is 260 / 1000\n",
      "Loss is -120.21324157714844\n",
      "Epoch is 261 / 1000\n",
      "Loss is -149.2895965576172\n",
      "Epoch is 262 / 1000\n",
      "Loss is -132.16998291015625\n",
      "Epoch is 263 / 1000\n",
      "Loss is -146.32382202148438\n",
      "Epoch is 264 / 1000\n",
      "Loss is -101.90239715576172\n",
      "Epoch is 265 / 1000\n",
      "Loss is -96.82249450683594\n",
      "Epoch is 266 / 1000\n",
      "Loss is -97.83573150634766\n",
      "Epoch is 267 / 1000\n",
      "Loss is -133.75424194335938\n",
      "Epoch is 268 / 1000\n",
      "Loss is -133.3839569091797\n",
      "Epoch is 269 / 1000\n",
      "Loss is -122.66253662109375\n",
      "Epoch is 270 / 1000\n",
      "Loss is -105.89279174804688\n",
      "Epoch is 271 / 1000\n",
      "Loss is -143.20587158203125\n",
      "Epoch is 272 / 1000\n",
      "Loss is -141.02947998046875\n",
      "Epoch is 273 / 1000\n",
      "Loss is -142.14578247070312\n",
      "Epoch is 274 / 1000\n",
      "Loss is -112.167724609375\n",
      "Epoch is 275 / 1000\n",
      "Loss is -158.50506591796875\n",
      "Epoch is 276 / 1000\n",
      "Loss is -158.443115234375\n",
      "Epoch is 277 / 1000\n",
      "Loss is -134.27603149414062\n",
      "Epoch is 278 / 1000\n",
      "Loss is -52.49144744873047\n",
      "Epoch is 279 / 1000\n",
      "Loss is -134.06912231445312\n",
      "Epoch is 280 / 1000\n",
      "Loss is -130.52581787109375\n",
      "Epoch is 281 / 1000\n",
      "Loss is -127.42535400390625\n",
      "Epoch is 282 / 1000\n",
      "Loss is -129.06678771972656\n",
      "Epoch is 283 / 1000\n",
      "Loss is -165.49099731445312\n",
      "Epoch is 284 / 1000\n",
      "Loss is -141.10853576660156\n",
      "Epoch is 285 / 1000\n",
      "Loss is -151.08045959472656\n",
      "Epoch is 286 / 1000\n",
      "Loss is -149.7916259765625\n",
      "Epoch is 287 / 1000\n",
      "Loss is -100.99284362792969\n",
      "Epoch is 288 / 1000\n",
      "Loss is -92.59791564941406\n",
      "Epoch is 289 / 1000\n",
      "Loss is -83.224853515625\n",
      "Epoch is 290 / 1000\n",
      "Loss is -140.03282165527344\n",
      "Epoch is 291 / 1000\n",
      "Loss is -103.06430053710938\n",
      "Epoch is 292 / 1000\n",
      "Loss is -95.20707702636719\n",
      "Epoch is 293 / 1000\n",
      "Loss is -135.3031463623047\n",
      "Epoch is 294 / 1000\n",
      "Loss is -171.5795440673828\n",
      "Epoch is 295 / 1000\n",
      "Loss is -107.78102111816406\n",
      "Epoch is 296 / 1000\n",
      "Loss is -147.75485229492188\n",
      "Epoch is 297 / 1000\n",
      "Loss is -127.93109130859375\n",
      "Epoch is 298 / 1000\n",
      "Loss is -169.79336547851562\n",
      "Epoch is 299 / 1000\n",
      "Loss is -137.3561553955078\n",
      "Epoch is 300 / 1000\n",
      "Loss is -169.428955078125\n",
      "Epoch is 301 / 1000\n",
      "Loss is -188.63539123535156\n",
      "Epoch is 302 / 1000\n",
      "Loss is -127.36033630371094\n",
      "Epoch is 303 / 1000\n",
      "Loss is -105.32103729248047\n",
      "Epoch is 304 / 1000\n",
      "Loss is -138.64541625976562\n",
      "Epoch is 305 / 1000\n",
      "Loss is -124.28070068359375\n",
      "Epoch is 306 / 1000\n",
      "Loss is -141.9752960205078\n",
      "Epoch is 307 / 1000\n",
      "Loss is -157.9136199951172\n",
      "Epoch is 308 / 1000\n",
      "Loss is -98.21153259277344\n",
      "Epoch is 309 / 1000\n",
      "Loss is -133.03614807128906\n",
      "Epoch is 310 / 1000\n",
      "Loss is -96.941650390625\n",
      "Epoch is 311 / 1000\n",
      "Loss is -131.54063415527344\n",
      "Epoch is 312 / 1000\n",
      "Loss is -75.65609741210938\n",
      "Epoch is 313 / 1000\n",
      "Loss is -123.11811828613281\n",
      "Epoch is 314 / 1000\n",
      "Loss is -128.31031799316406\n",
      "Epoch is 315 / 1000\n",
      "Loss is -150.68972778320312\n",
      "Epoch is 316 / 1000\n",
      "Loss is -121.89701843261719\n",
      "Epoch is 317 / 1000\n",
      "Loss is -165.29417419433594\n",
      "Epoch is 318 / 1000\n",
      "Loss is -163.52598571777344\n",
      "Epoch is 319 / 1000\n",
      "Loss is -116.00436401367188\n",
      "Epoch is 320 / 1000\n",
      "Loss is -110.70664978027344\n",
      "Epoch is 321 / 1000\n",
      "Loss is -163.42855834960938\n",
      "Epoch is 322 / 1000\n",
      "Loss is -116.66195678710938\n",
      "Epoch is 323 / 1000\n",
      "Loss is -134.83712768554688\n",
      "Epoch is 324 / 1000\n",
      "Loss is -146.35716247558594\n",
      "Epoch is 325 / 1000\n",
      "Loss is -149.8142547607422\n",
      "Epoch is 326 / 1000\n",
      "Loss is -104.64051818847656\n",
      "Epoch is 327 / 1000\n",
      "Loss is -126.00812530517578\n",
      "Epoch is 328 / 1000\n",
      "Loss is -117.41016387939453\n",
      "Epoch is 329 / 1000\n",
      "Loss is -162.87893676757812\n",
      "Epoch is 330 / 1000\n",
      "Loss is -122.6390151977539\n",
      "Epoch is 331 / 1000\n",
      "Loss is -160.32334899902344\n",
      "Epoch is 332 / 1000\n",
      "Loss is -92.40222930908203\n",
      "Epoch is 333 / 1000\n",
      "Loss is -109.22773742675781\n",
      "Epoch is 334 / 1000\n",
      "Loss is -158.7952880859375\n",
      "Epoch is 335 / 1000\n",
      "Loss is -135.15652465820312\n",
      "Epoch is 336 / 1000\n",
      "Loss is -143.89877319335938\n",
      "Epoch is 337 / 1000\n",
      "Loss is -100.18083953857422\n",
      "Epoch is 338 / 1000\n",
      "Loss is -136.87774658203125\n",
      "Epoch is 339 / 1000\n",
      "Loss is -182.49453735351562\n",
      "Epoch is 340 / 1000\n",
      "Loss is -169.76583862304688\n",
      "Epoch is 341 / 1000\n",
      "Loss is -152.7066650390625\n",
      "Epoch is 342 / 1000\n",
      "Loss is -109.01690673828125\n",
      "Epoch is 343 / 1000\n",
      "Loss is -85.71368408203125\n",
      "Epoch is 344 / 1000\n",
      "Loss is -164.8840789794922\n",
      "Epoch is 345 / 1000\n",
      "Loss is -89.05113220214844\n",
      "Epoch is 346 / 1000\n",
      "Loss is -164.05557250976562\n",
      "Epoch is 347 / 1000\n",
      "Loss is -110.22856140136719\n",
      "Epoch is 348 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is -115.83354187011719\n",
      "Epoch is 349 / 1000\n",
      "Loss is -98.54496765136719\n",
      "Epoch is 350 / 1000\n",
      "Loss is -119.78644561767578\n",
      "Epoch is 351 / 1000\n",
      "Loss is -99.72944641113281\n",
      "Epoch is 352 / 1000\n",
      "Loss is -121.17254638671875\n",
      "Epoch is 353 / 1000\n",
      "Loss is -163.587158203125\n",
      "Epoch is 354 / 1000\n",
      "Loss is -112.46710205078125\n",
      "Epoch is 355 / 1000\n",
      "Loss is -163.75608825683594\n",
      "Epoch is 356 / 1000\n",
      "Loss is -143.28781127929688\n",
      "Epoch is 357 / 1000\n",
      "Loss is -132.28189086914062\n",
      "Epoch is 358 / 1000\n",
      "Loss is -139.22348022460938\n",
      "Epoch is 359 / 1000\n",
      "Loss is -156.41766357421875\n",
      "Epoch is 360 / 1000\n",
      "Loss is -105.92832946777344\n",
      "Epoch is 361 / 1000\n",
      "Loss is -127.9653549194336\n",
      "Epoch is 362 / 1000\n",
      "Loss is -103.49098205566406\n",
      "Epoch is 363 / 1000\n",
      "Loss is -146.93231201171875\n",
      "Epoch is 364 / 1000\n",
      "Loss is -106.42233276367188\n",
      "Epoch is 365 / 1000\n",
      "Loss is -120.21367645263672\n",
      "Epoch is 366 / 1000\n",
      "Loss is -114.15951538085938\n",
      "Epoch is 367 / 1000\n",
      "Loss is -141.37828063964844\n",
      "Epoch is 368 / 1000\n",
      "Loss is -156.71868896484375\n",
      "Epoch is 369 / 1000\n",
      "Loss is -135.7931671142578\n",
      "Epoch is 370 / 1000\n",
      "Loss is -96.15975952148438\n",
      "Epoch is 371 / 1000\n",
      "Loss is -190.34024047851562\n",
      "Epoch is 372 / 1000\n",
      "Loss is -152.82705688476562\n",
      "Epoch is 373 / 1000\n",
      "Loss is -141.2174835205078\n",
      "Epoch is 374 / 1000\n",
      "Loss is -119.3672866821289\n",
      "Epoch is 375 / 1000\n",
      "Loss is -158.78790283203125\n",
      "Epoch is 376 / 1000\n",
      "Loss is -126.36995697021484\n",
      "Epoch is 377 / 1000\n",
      "Loss is -113.04981231689453\n",
      "Epoch is 378 / 1000\n",
      "Loss is -148.12420654296875\n",
      "Epoch is 379 / 1000\n",
      "Loss is -169.77761840820312\n",
      "Epoch is 380 / 1000\n",
      "Loss is -140.09371948242188\n",
      "Epoch is 381 / 1000\n",
      "Loss is -118.71516418457031\n",
      "Epoch is 382 / 1000\n",
      "Loss is -158.32406616210938\n",
      "Epoch is 383 / 1000\n",
      "Loss is -124.74214172363281\n",
      "Epoch is 384 / 1000\n",
      "Loss is -179.09234619140625\n",
      "Epoch is 385 / 1000\n",
      "Loss is -132.60552978515625\n",
      "Epoch is 386 / 1000\n",
      "Loss is -137.91912841796875\n",
      "Epoch is 387 / 1000\n",
      "Loss is -121.55007934570312\n",
      "Epoch is 388 / 1000\n",
      "Loss is -158.1441192626953\n",
      "Epoch is 389 / 1000\n",
      "Loss is -137.5133514404297\n",
      "Epoch is 390 / 1000\n",
      "Loss is -140.45291137695312\n",
      "Epoch is 391 / 1000\n",
      "Loss is -119.09003448486328\n",
      "Epoch is 392 / 1000\n",
      "Loss is -158.57968139648438\n",
      "Epoch is 393 / 1000\n",
      "Loss is -138.70262145996094\n",
      "Epoch is 394 / 1000\n",
      "Loss is -190.28033447265625\n",
      "Epoch is 395 / 1000\n",
      "Loss is -141.4547119140625\n",
      "Epoch is 396 / 1000\n",
      "Loss is -155.5733642578125\n",
      "Epoch is 397 / 1000\n",
      "Loss is -174.8746337890625\n",
      "Epoch is 398 / 1000\n",
      "Loss is -152.81344604492188\n",
      "Epoch is 399 / 1000\n",
      "Loss is -136.96112060546875\n",
      "Epoch is 400 / 1000\n",
      "Loss is -136.3735809326172\n",
      "Epoch is 401 / 1000\n",
      "Loss is -147.08428955078125\n",
      "Epoch is 402 / 1000\n",
      "Loss is -117.42245483398438\n",
      "Epoch is 403 / 1000\n",
      "Loss is -140.17066955566406\n",
      "Epoch is 404 / 1000\n",
      "Loss is -113.1392822265625\n",
      "Epoch is 405 / 1000\n",
      "Loss is -145.273681640625\n",
      "Epoch is 406 / 1000\n",
      "Loss is -162.36865234375\n",
      "Epoch is 407 / 1000\n",
      "Loss is -118.63150024414062\n",
      "Epoch is 408 / 1000\n",
      "Loss is -159.37677001953125\n",
      "Epoch is 409 / 1000\n",
      "Loss is -84.18521881103516\n",
      "Epoch is 410 / 1000\n",
      "Loss is -134.39285278320312\n",
      "Epoch is 411 / 1000\n",
      "Loss is -132.36444091796875\n",
      "Epoch is 412 / 1000\n",
      "Loss is -137.277099609375\n",
      "Epoch is 413 / 1000\n",
      "Loss is -168.62950134277344\n",
      "Epoch is 414 / 1000\n",
      "Loss is -150.5484619140625\n",
      "Epoch is 415 / 1000\n",
      "Loss is -178.08900451660156\n",
      "Epoch is 416 / 1000\n",
      "Loss is -118.09221649169922\n",
      "Epoch is 417 / 1000\n",
      "Loss is -128.43418884277344\n",
      "Epoch is 418 / 1000\n",
      "Loss is -136.93775939941406\n",
      "Epoch is 419 / 1000\n",
      "Loss is -161.52906799316406\n",
      "Epoch is 420 / 1000\n",
      "Loss is -166.31680297851562\n",
      "Epoch is 421 / 1000\n",
      "Loss is -118.05237579345703\n",
      "Epoch is 422 / 1000\n",
      "Loss is -138.68682861328125\n",
      "Epoch is 423 / 1000\n",
      "Loss is -173.80284118652344\n",
      "Epoch is 424 / 1000\n",
      "Loss is -151.38819885253906\n",
      "Epoch is 425 / 1000\n",
      "Loss is -142.7721710205078\n",
      "Epoch is 426 / 1000\n",
      "Loss is -191.5111541748047\n",
      "Epoch is 427 / 1000\n",
      "Loss is -162.837158203125\n",
      "Epoch is 428 / 1000\n",
      "Loss is -182.42813110351562\n",
      "Epoch is 429 / 1000\n",
      "Loss is -136.09523010253906\n",
      "Epoch is 430 / 1000\n",
      "Loss is -143.08157348632812\n",
      "Epoch is 431 / 1000\n",
      "Loss is -137.22531127929688\n",
      "Epoch is 432 / 1000\n",
      "Loss is -141.065185546875\n",
      "Epoch is 433 / 1000\n",
      "Loss is -163.74256896972656\n",
      "Epoch is 434 / 1000\n",
      "Loss is -167.6741485595703\n",
      "Epoch is 435 / 1000\n",
      "Loss is -124.95339965820312\n",
      "Epoch is 436 / 1000\n",
      "Loss is -161.2459716796875\n",
      "Epoch is 437 / 1000\n",
      "Loss is -149.7202911376953\n",
      "Epoch is 438 / 1000\n",
      "Loss is -149.81326293945312\n",
      "Epoch is 439 / 1000\n",
      "Loss is -122.40532684326172\n",
      "Epoch is 440 / 1000\n",
      "Loss is -123.09442138671875\n",
      "Epoch is 441 / 1000\n",
      "Loss is -220.88177490234375\n",
      "Epoch is 442 / 1000\n",
      "Loss is -158.2017822265625\n",
      "Epoch is 443 / 1000\n",
      "Loss is -157.65289306640625\n",
      "Epoch is 444 / 1000\n",
      "Loss is -89.79571533203125\n",
      "Epoch is 445 / 1000\n",
      "Loss is -174.2237091064453\n",
      "Epoch is 446 / 1000\n",
      "Loss is -143.98306274414062\n",
      "Epoch is 447 / 1000\n",
      "Loss is -160.49722290039062\n",
      "Epoch is 448 / 1000\n",
      "Loss is -142.72784423828125\n",
      "Epoch is 449 / 1000\n",
      "Loss is -164.16046142578125\n",
      "Epoch is 450 / 1000\n",
      "Loss is -172.49072265625\n",
      "Epoch is 451 / 1000\n",
      "Loss is -138.7021484375\n",
      "Epoch is 452 / 1000\n",
      "Loss is -144.67300415039062\n",
      "Epoch is 453 / 1000\n",
      "Loss is -159.9096221923828\n",
      "Epoch is 454 / 1000\n",
      "Loss is -115.29267883300781\n",
      "Epoch is 455 / 1000\n",
      "Loss is -161.87435913085938\n",
      "Epoch is 456 / 1000\n",
      "Loss is -109.26978302001953\n",
      "Epoch is 457 / 1000\n",
      "Loss is -188.168701171875\n",
      "Epoch is 458 / 1000\n",
      "Loss is -126.12081909179688\n",
      "Epoch is 459 / 1000\n",
      "Loss is -216.28567504882812\n",
      "Epoch is 460 / 1000\n",
      "Loss is -162.38092041015625\n",
      "Epoch is 461 / 1000\n",
      "Loss is -117.63966369628906\n",
      "Epoch is 462 / 1000\n",
      "Loss is -128.62576293945312\n",
      "Epoch is 463 / 1000\n",
      "Loss is -121.37250518798828\n",
      "Epoch is 464 / 1000\n",
      "Loss is -164.12889099121094\n",
      "Epoch is 465 / 1000\n",
      "Loss is -153.00448608398438\n",
      "Epoch is 466 / 1000\n",
      "Loss is -179.9571533203125\n",
      "Epoch is 467 / 1000\n",
      "Loss is -155.77316284179688\n",
      "Epoch is 468 / 1000\n",
      "Loss is -104.60728454589844\n",
      "Epoch is 469 / 1000\n",
      "Loss is -156.6943359375\n",
      "Epoch is 470 / 1000\n",
      "Loss is -143.4898681640625\n",
      "Epoch is 471 / 1000\n",
      "Loss is -157.5003204345703\n",
      "Epoch is 472 / 1000\n",
      "Loss is -167.81748962402344\n",
      "Epoch is 473 / 1000\n",
      "Loss is -136.54336547851562\n",
      "Epoch is 474 / 1000\n",
      "Loss is -149.39947509765625\n",
      "Epoch is 475 / 1000\n",
      "Loss is -151.36013793945312\n",
      "Epoch is 476 / 1000\n",
      "Loss is -105.37494659423828\n",
      "Epoch is 477 / 1000\n",
      "Loss is -164.92288208007812\n",
      "Epoch is 478 / 1000\n",
      "Loss is -169.5633544921875\n",
      "Epoch is 479 / 1000\n",
      "Loss is -123.230712890625\n",
      "Epoch is 480 / 1000\n",
      "Loss is -147.92098999023438\n",
      "Epoch is 481 / 1000\n",
      "Loss is -140.9207305908203\n",
      "Epoch is 482 / 1000\n",
      "Loss is -150.2295379638672\n",
      "Epoch is 483 / 1000\n",
      "Loss is -139.6875762939453\n",
      "Epoch is 484 / 1000\n",
      "Loss is -142.88063049316406\n",
      "Epoch is 485 / 1000\n",
      "Loss is -178.9821014404297\n",
      "Epoch is 486 / 1000\n",
      "Loss is -159.86940002441406\n",
      "Epoch is 487 / 1000\n",
      "Loss is -152.6432647705078\n",
      "Epoch is 488 / 1000\n",
      "Loss is -142.63348388671875\n",
      "Epoch is 489 / 1000\n",
      "Loss is -179.1677703857422\n",
      "Epoch is 490 / 1000\n",
      "Loss is -113.8145751953125\n",
      "Epoch is 491 / 1000\n",
      "Loss is -188.59188842773438\n",
      "Epoch is 492 / 1000\n",
      "Loss is -171.09893798828125\n",
      "Epoch is 493 / 1000\n",
      "Loss is -112.15419006347656\n",
      "Epoch is 494 / 1000\n",
      "Loss is -113.57966613769531\n",
      "Epoch is 495 / 1000\n",
      "Loss is -130.84512329101562\n",
      "Epoch is 496 / 1000\n",
      "Loss is -193.32485961914062\n",
      "Epoch is 497 / 1000\n",
      "Loss is -165.4798583984375\n",
      "Epoch is 498 / 1000\n",
      "Loss is -178.41175842285156\n",
      "Epoch is 499 / 1000\n",
      "Loss is -164.5316925048828\n",
      "Epoch is 500 / 1000\n",
      "Loss is -169.71890258789062\n",
      "Epoch is 501 / 1000\n",
      "Loss is -140.96815490722656\n",
      "Epoch is 502 / 1000\n",
      "Loss is -199.65231323242188\n",
      "Epoch is 503 / 1000\n",
      "Loss is -187.1553955078125\n",
      "Epoch is 504 / 1000\n",
      "Loss is -86.64497375488281\n",
      "Epoch is 505 / 1000\n",
      "Loss is -125.41889190673828\n",
      "Epoch is 506 / 1000\n",
      "Loss is -150.28842163085938\n",
      "Epoch is 507 / 1000\n",
      "Loss is -123.05854034423828\n",
      "Epoch is 508 / 1000\n",
      "Loss is -149.39901733398438\n",
      "Epoch is 509 / 1000\n",
      "Loss is -171.08639526367188\n",
      "Epoch is 510 / 1000\n",
      "Loss is -134.0707244873047\n",
      "Epoch is 511 / 1000\n",
      "Loss is -160.13624572753906\n",
      "Epoch is 512 / 1000\n",
      "Loss is -142.13125610351562\n",
      "Epoch is 513 / 1000\n",
      "Loss is -141.70285034179688\n",
      "Epoch is 514 / 1000\n",
      "Loss is -147.22853088378906\n",
      "Epoch is 515 / 1000\n",
      "Loss is -143.23226928710938\n",
      "Epoch is 516 / 1000\n",
      "Loss is -163.08212280273438\n",
      "Epoch is 517 / 1000\n",
      "Loss is -170.95059204101562\n",
      "Epoch is 518 / 1000\n",
      "Loss is -129.9915771484375\n",
      "Epoch is 519 / 1000\n",
      "Loss is -177.26748657226562\n",
      "Epoch is 520 / 1000\n",
      "Loss is -147.5128936767578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 521 / 1000\n",
      "Loss is -114.80482482910156\n",
      "Epoch is 522 / 1000\n",
      "Loss is -161.10739135742188\n",
      "Epoch is 523 / 1000\n",
      "Loss is -128.6144256591797\n",
      "Epoch is 524 / 1000\n",
      "Loss is -139.0962677001953\n",
      "Epoch is 525 / 1000\n",
      "Loss is -146.73056030273438\n",
      "Epoch is 526 / 1000\n",
      "Loss is -194.08538818359375\n",
      "Epoch is 527 / 1000\n",
      "Loss is -126.8163070678711\n",
      "Epoch is 528 / 1000\n",
      "Loss is -156.38290405273438\n",
      "Epoch is 529 / 1000\n",
      "Loss is -163.72119140625\n",
      "Epoch is 530 / 1000\n",
      "Loss is -141.05258178710938\n",
      "Epoch is 531 / 1000\n",
      "Loss is -161.20753479003906\n",
      "Epoch is 532 / 1000\n",
      "Loss is -174.8356170654297\n",
      "Epoch is 533 / 1000\n",
      "Loss is -139.1293182373047\n",
      "Epoch is 534 / 1000\n",
      "Loss is -133.1656036376953\n",
      "Epoch is 535 / 1000\n",
      "Loss is -196.45338439941406\n",
      "Epoch is 536 / 1000\n",
      "Loss is -182.12884521484375\n",
      "Epoch is 537 / 1000\n",
      "Loss is -176.4110870361328\n",
      "Epoch is 538 / 1000\n",
      "Loss is -138.0447998046875\n",
      "Epoch is 539 / 1000\n",
      "Loss is -160.40509033203125\n",
      "Epoch is 540 / 1000\n",
      "Loss is -156.82293701171875\n",
      "Epoch is 541 / 1000\n",
      "Loss is -155.01220703125\n",
      "Epoch is 542 / 1000\n",
      "Loss is -169.22317504882812\n",
      "Epoch is 543 / 1000\n",
      "Loss is -176.05421447753906\n",
      "Epoch is 544 / 1000\n",
      "Loss is -87.74545288085938\n",
      "Epoch is 545 / 1000\n",
      "Loss is -191.7337646484375\n",
      "Epoch is 546 / 1000\n",
      "Loss is -118.20814514160156\n",
      "Epoch is 547 / 1000\n",
      "Loss is -128.8723602294922\n",
      "Epoch is 548 / 1000\n",
      "Loss is -153.4723663330078\n",
      "Epoch is 549 / 1000\n",
      "Loss is -213.3262481689453\n",
      "Epoch is 550 / 1000\n",
      "Loss is -129.91282653808594\n",
      "Epoch is 551 / 1000\n",
      "Loss is -138.619873046875\n",
      "Epoch is 552 / 1000\n",
      "Loss is -164.38076782226562\n",
      "Epoch is 553 / 1000\n",
      "Loss is -130.43505859375\n",
      "Epoch is 554 / 1000\n",
      "Loss is -187.92221069335938\n",
      "Epoch is 555 / 1000\n",
      "Loss is -160.8612823486328\n",
      "Epoch is 556 / 1000\n",
      "Loss is -162.99560546875\n",
      "Epoch is 557 / 1000\n",
      "Loss is -159.012451171875\n",
      "Epoch is 558 / 1000\n",
      "Loss is -181.23277282714844\n",
      "Epoch is 559 / 1000\n",
      "Loss is -152.7931365966797\n",
      "Epoch is 560 / 1000\n",
      "Loss is -132.5482635498047\n",
      "Epoch is 561 / 1000\n",
      "Loss is -166.53233337402344\n",
      "Epoch is 562 / 1000\n",
      "Loss is -148.60140991210938\n",
      "Epoch is 563 / 1000\n",
      "Loss is -190.01490783691406\n",
      "Epoch is 564 / 1000\n",
      "Loss is -160.76451110839844\n",
      "Epoch is 565 / 1000\n",
      "Loss is -157.38226318359375\n",
      "Epoch is 566 / 1000\n",
      "Loss is -130.9537811279297\n",
      "Epoch is 567 / 1000\n",
      "Loss is -122.51190185546875\n",
      "Epoch is 568 / 1000\n",
      "Loss is -129.99630737304688\n",
      "Epoch is 569 / 1000\n",
      "Loss is -114.71113586425781\n",
      "Epoch is 570 / 1000\n",
      "Loss is -168.52227783203125\n",
      "Epoch is 571 / 1000\n",
      "Loss is -158.19119262695312\n",
      "Epoch is 572 / 1000\n",
      "Loss is -166.6027069091797\n",
      "Epoch is 573 / 1000\n",
      "Loss is -189.61744689941406\n",
      "Epoch is 574 / 1000\n",
      "Loss is -186.70965576171875\n",
      "Epoch is 575 / 1000\n",
      "Loss is -211.43121337890625\n",
      "Epoch is 576 / 1000\n",
      "Loss is -129.3922882080078\n",
      "Epoch is 577 / 1000\n",
      "Loss is -139.88795471191406\n",
      "Epoch is 578 / 1000\n",
      "Loss is -146.3308563232422\n",
      "Epoch is 579 / 1000\n",
      "Loss is -174.11557006835938\n",
      "Epoch is 580 / 1000\n",
      "Loss is -161.94869995117188\n",
      "Epoch is 581 / 1000\n",
      "Loss is -162.75811767578125\n",
      "Epoch is 582 / 1000\n",
      "Loss is -159.9553985595703\n",
      "Epoch is 583 / 1000\n",
      "Loss is -167.02236938476562\n",
      "Epoch is 584 / 1000\n",
      "Loss is -160.43829345703125\n",
      "Epoch is 585 / 1000\n",
      "Loss is -159.14404296875\n",
      "Epoch is 586 / 1000\n",
      "Loss is -126.81466674804688\n",
      "Epoch is 587 / 1000\n",
      "Loss is -151.14556884765625\n",
      "Epoch is 588 / 1000\n",
      "Loss is -182.54013061523438\n",
      "Epoch is 589 / 1000\n",
      "Loss is -162.50289916992188\n",
      "Epoch is 590 / 1000\n",
      "Loss is -137.03546142578125\n",
      "Epoch is 591 / 1000\n",
      "Loss is -136.283935546875\n",
      "Epoch is 592 / 1000\n",
      "Loss is -170.948974609375\n",
      "Epoch is 593 / 1000\n",
      "Loss is -94.77236938476562\n",
      "Epoch is 594 / 1000\n",
      "Loss is -145.60910034179688\n",
      "Epoch is 595 / 1000\n",
      "Loss is -173.6622314453125\n",
      "Epoch is 596 / 1000\n",
      "Loss is -192.1476287841797\n",
      "Epoch is 597 / 1000\n",
      "Loss is -170.5806884765625\n",
      "Epoch is 598 / 1000\n",
      "Loss is -111.41669464111328\n",
      "Epoch is 599 / 1000\n",
      "Loss is -161.36102294921875\n",
      "Epoch is 600 / 1000\n",
      "Loss is -163.38980102539062\n",
      "Epoch is 601 / 1000\n",
      "Loss is -145.23818969726562\n",
      "Epoch is 602 / 1000\n",
      "Loss is -166.12815856933594\n",
      "Epoch is 603 / 1000\n",
      "Loss is -139.87680053710938\n",
      "Epoch is 604 / 1000\n",
      "Loss is -160.38662719726562\n",
      "Epoch is 605 / 1000\n",
      "Loss is -144.05894470214844\n",
      "Epoch is 606 / 1000\n",
      "Loss is -116.89336395263672\n",
      "Epoch is 607 / 1000\n",
      "Loss is -201.54519653320312\n",
      "Epoch is 608 / 1000\n",
      "Loss is -167.4194793701172\n",
      "Epoch is 609 / 1000\n",
      "Loss is -151.57421875\n",
      "Epoch is 610 / 1000\n",
      "Loss is -132.9138641357422\n",
      "Epoch is 611 / 1000\n",
      "Loss is -186.95806884765625\n",
      "Epoch is 612 / 1000\n",
      "Loss is -125.51854705810547\n",
      "Epoch is 613 / 1000\n",
      "Loss is -145.91339111328125\n",
      "Epoch is 614 / 1000\n",
      "Loss is -158.31057739257812\n",
      "Epoch is 615 / 1000\n",
      "Loss is -185.7435760498047\n",
      "Epoch is 616 / 1000\n",
      "Loss is -192.51812744140625\n",
      "Epoch is 617 / 1000\n",
      "Loss is -150.56765747070312\n",
      "Epoch is 618 / 1000\n",
      "Loss is -182.39430236816406\n",
      "Epoch is 619 / 1000\n",
      "Loss is -171.46925354003906\n",
      "Epoch is 620 / 1000\n",
      "Loss is -168.84608459472656\n",
      "Epoch is 621 / 1000\n",
      "Loss is -183.6450958251953\n",
      "Epoch is 622 / 1000\n",
      "Loss is -174.60882568359375\n",
      "Epoch is 623 / 1000\n",
      "Loss is -148.6721954345703\n",
      "Epoch is 624 / 1000\n",
      "Loss is -143.84288024902344\n",
      "Epoch is 625 / 1000\n",
      "Loss is -151.11422729492188\n",
      "Epoch is 626 / 1000\n",
      "Loss is -159.6671600341797\n",
      "Epoch is 627 / 1000\n",
      "Loss is -174.38003540039062\n",
      "Epoch is 628 / 1000\n",
      "Loss is -181.87257385253906\n",
      "Epoch is 629 / 1000\n",
      "Loss is -138.11607360839844\n",
      "Epoch is 630 / 1000\n",
      "Loss is -167.49205017089844\n",
      "Epoch is 631 / 1000\n",
      "Loss is -135.47708129882812\n",
      "Epoch is 632 / 1000\n",
      "Loss is -158.80490112304688\n",
      "Epoch is 633 / 1000\n",
      "Loss is -169.6536865234375\n",
      "Epoch is 634 / 1000\n",
      "Loss is -176.38717651367188\n",
      "Epoch is 635 / 1000\n",
      "Loss is -120.422607421875\n",
      "Epoch is 636 / 1000\n",
      "Loss is -218.44125366210938\n",
      "Epoch is 637 / 1000\n",
      "Loss is -131.85488891601562\n",
      "Epoch is 638 / 1000\n",
      "Loss is -108.23062133789062\n",
      "Epoch is 639 / 1000\n",
      "Loss is -172.89129638671875\n",
      "Epoch is 640 / 1000\n",
      "Loss is -160.45936584472656\n",
      "Epoch is 641 / 1000\n",
      "Loss is -168.9853057861328\n",
      "Epoch is 642 / 1000\n",
      "Loss is -108.93743896484375\n",
      "Epoch is 643 / 1000\n",
      "Loss is -146.96949768066406\n",
      "Epoch is 644 / 1000\n",
      "Loss is -183.63958740234375\n",
      "Epoch is 645 / 1000\n",
      "Loss is -168.81939697265625\n",
      "Epoch is 646 / 1000\n",
      "Loss is -165.0679931640625\n",
      "Epoch is 647 / 1000\n",
      "Loss is -166.54322814941406\n",
      "Epoch is 648 / 1000\n",
      "Loss is -153.22848510742188\n",
      "Epoch is 649 / 1000\n",
      "Loss is -121.06253051757812\n",
      "Epoch is 650 / 1000\n",
      "Loss is -144.755615234375\n",
      "Epoch is 651 / 1000\n",
      "Loss is -157.4268798828125\n",
      "Epoch is 652 / 1000\n",
      "Loss is -157.49664306640625\n",
      "Epoch is 653 / 1000\n",
      "Loss is -175.93194580078125\n",
      "Epoch is 654 / 1000\n",
      "Loss is -167.6630859375\n",
      "Epoch is 655 / 1000\n",
      "Loss is -153.0378875732422\n",
      "Epoch is 656 / 1000\n",
      "Loss is -116.13653564453125\n",
      "Epoch is 657 / 1000\n",
      "Loss is -170.86550903320312\n",
      "Epoch is 658 / 1000\n",
      "Loss is -157.4024658203125\n",
      "Epoch is 659 / 1000\n",
      "Loss is -197.17445373535156\n",
      "Epoch is 660 / 1000\n",
      "Loss is -168.1970672607422\n",
      "Epoch is 661 / 1000\n",
      "Loss is -147.46466064453125\n",
      "Epoch is 662 / 1000\n",
      "Loss is -221.64385986328125\n",
      "Epoch is 663 / 1000\n",
      "Loss is -131.57662963867188\n",
      "Epoch is 664 / 1000\n",
      "Loss is -145.10562133789062\n",
      "Epoch is 665 / 1000\n",
      "Loss is -147.6589813232422\n",
      "Epoch is 666 / 1000\n",
      "Loss is -126.04936218261719\n",
      "Epoch is 667 / 1000\n",
      "Loss is -140.24635314941406\n",
      "Epoch is 668 / 1000\n",
      "Loss is -163.79666137695312\n",
      "Epoch is 669 / 1000\n",
      "Loss is -157.57171630859375\n",
      "Epoch is 670 / 1000\n",
      "Loss is -173.64759826660156\n",
      "Epoch is 671 / 1000\n",
      "Loss is -113.32643127441406\n",
      "Epoch is 672 / 1000\n",
      "Loss is -207.5970916748047\n",
      "Epoch is 673 / 1000\n",
      "Loss is -159.75657653808594\n",
      "Epoch is 674 / 1000\n",
      "Loss is -186.20654296875\n",
      "Epoch is 675 / 1000\n",
      "Loss is -154.05587768554688\n",
      "Epoch is 676 / 1000\n",
      "Loss is -146.06451416015625\n",
      "Epoch is 677 / 1000\n",
      "Loss is -132.6091766357422\n",
      "Epoch is 678 / 1000\n",
      "Loss is -127.14698791503906\n",
      "Epoch is 679 / 1000\n",
      "Loss is -135.3519287109375\n",
      "Epoch is 680 / 1000\n",
      "Loss is -174.05149841308594\n",
      "Epoch is 681 / 1000\n",
      "Loss is -191.94979858398438\n",
      "Epoch is 682 / 1000\n",
      "Loss is -161.78326416015625\n",
      "Epoch is 683 / 1000\n",
      "Loss is -162.30117797851562\n",
      "Epoch is 684 / 1000\n",
      "Loss is -163.42437744140625\n",
      "Epoch is 685 / 1000\n",
      "Loss is -202.32110595703125\n",
      "Epoch is 686 / 1000\n",
      "Loss is -158.93460083007812\n",
      "Epoch is 687 / 1000\n",
      "Loss is -190.3494110107422\n",
      "Epoch is 688 / 1000\n",
      "Loss is -168.3733673095703\n",
      "Epoch is 689 / 1000\n",
      "Loss is -154.89431762695312\n",
      "Epoch is 690 / 1000\n",
      "Loss is -147.92698669433594\n",
      "Epoch is 691 / 1000\n",
      "Loss is -146.64329528808594\n",
      "Epoch is 692 / 1000\n",
      "Loss is -153.96791076660156\n",
      "Epoch is 693 / 1000\n",
      "Loss is -149.59873962402344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 694 / 1000\n",
      "Loss is -133.94357299804688\n",
      "Epoch is 695 / 1000\n",
      "Loss is -208.66111755371094\n",
      "Epoch is 696 / 1000\n",
      "Loss is -130.96006774902344\n",
      "Epoch is 697 / 1000\n",
      "Loss is -186.13192749023438\n",
      "Epoch is 698 / 1000\n",
      "Loss is -131.01242065429688\n",
      "Epoch is 699 / 1000\n",
      "Loss is -157.34271240234375\n",
      "Epoch is 700 / 1000\n",
      "Loss is -172.0540771484375\n",
      "Epoch is 701 / 1000\n",
      "Loss is -155.59613037109375\n",
      "Epoch is 702 / 1000\n",
      "Loss is -147.3474884033203\n",
      "Epoch is 703 / 1000\n",
      "Loss is -154.35630798339844\n",
      "Epoch is 704 / 1000\n",
      "Loss is -181.7483367919922\n",
      "Epoch is 705 / 1000\n",
      "Loss is -181.8618621826172\n",
      "Epoch is 706 / 1000\n",
      "Loss is -179.08154296875\n",
      "Epoch is 707 / 1000\n",
      "Loss is -155.7711181640625\n",
      "Epoch is 708 / 1000\n",
      "Loss is -200.65159606933594\n",
      "Epoch is 709 / 1000\n",
      "Loss is -128.1022491455078\n",
      "Epoch is 710 / 1000\n",
      "Loss is -153.3594207763672\n",
      "Epoch is 711 / 1000\n",
      "Loss is -168.83518981933594\n",
      "Epoch is 712 / 1000\n",
      "Loss is -184.97735595703125\n",
      "Epoch is 713 / 1000\n",
      "Loss is -149.26080322265625\n",
      "Epoch is 714 / 1000\n",
      "Loss is -161.08526611328125\n",
      "Epoch is 715 / 1000\n",
      "Loss is -165.68814086914062\n",
      "Epoch is 716 / 1000\n",
      "Loss is -197.90597534179688\n",
      "Epoch is 717 / 1000\n",
      "Loss is -146.0842742919922\n",
      "Epoch is 718 / 1000\n",
      "Loss is -131.458251953125\n",
      "Epoch is 719 / 1000\n",
      "Loss is -199.98873901367188\n",
      "Epoch is 720 / 1000\n",
      "Loss is -122.75148010253906\n",
      "Epoch is 721 / 1000\n",
      "Loss is -176.97268676757812\n",
      "Epoch is 722 / 1000\n",
      "Loss is -153.57164001464844\n",
      "Epoch is 723 / 1000\n",
      "Loss is -175.5225830078125\n",
      "Epoch is 724 / 1000\n",
      "Loss is -180.63052368164062\n",
      "Epoch is 725 / 1000\n",
      "Loss is -206.32357788085938\n",
      "Epoch is 726 / 1000\n",
      "Loss is -120.88116455078125\n",
      "Epoch is 727 / 1000\n",
      "Loss is -180.33824157714844\n",
      "Epoch is 728 / 1000\n",
      "Loss is -230.20977783203125\n",
      "Epoch is 729 / 1000\n",
      "Loss is -160.54498291015625\n",
      "Epoch is 730 / 1000\n",
      "Loss is -180.6573944091797\n",
      "Epoch is 731 / 1000\n",
      "Loss is -198.78684997558594\n",
      "Epoch is 732 / 1000\n",
      "Loss is -185.10023498535156\n",
      "Epoch is 733 / 1000\n",
      "Loss is -146.36883544921875\n",
      "Epoch is 734 / 1000\n",
      "Loss is -151.96360778808594\n",
      "Epoch is 735 / 1000\n",
      "Loss is -147.004638671875\n",
      "Epoch is 736 / 1000\n",
      "Loss is -157.33944702148438\n",
      "Epoch is 737 / 1000\n",
      "Loss is -176.5309295654297\n",
      "Epoch is 738 / 1000\n",
      "Loss is -209.92514038085938\n",
      "Epoch is 739 / 1000\n",
      "Loss is -218.95567321777344\n",
      "Epoch is 740 / 1000\n",
      "Loss is -201.12606811523438\n",
      "Epoch is 741 / 1000\n",
      "Loss is -133.1739501953125\n",
      "Epoch is 742 / 1000\n",
      "Loss is -126.6304702758789\n",
      "Epoch is 743 / 1000\n",
      "Loss is -161.60606384277344\n",
      "Epoch is 744 / 1000\n",
      "Loss is -160.27957153320312\n",
      "Epoch is 745 / 1000\n",
      "Loss is -235.37533569335938\n",
      "Epoch is 746 / 1000\n",
      "Loss is -193.63526916503906\n",
      "Epoch is 747 / 1000\n",
      "Loss is -155.60140991210938\n",
      "Epoch is 748 / 1000\n",
      "Loss is -181.41531372070312\n",
      "Epoch is 749 / 1000\n",
      "Loss is -187.30345153808594\n",
      "Epoch is 750 / 1000\n",
      "Loss is -133.3941192626953\n",
      "Epoch is 751 / 1000\n",
      "Loss is -186.45556640625\n",
      "Epoch is 752 / 1000\n",
      "Loss is -162.72320556640625\n",
      "Epoch is 753 / 1000\n",
      "Loss is -159.28231811523438\n",
      "Epoch is 754 / 1000\n",
      "Loss is -205.13818359375\n",
      "Epoch is 755 / 1000\n",
      "Loss is -179.13580322265625\n",
      "Epoch is 756 / 1000\n",
      "Loss is -165.7125701904297\n",
      "Epoch is 757 / 1000\n",
      "Loss is -189.26815795898438\n",
      "Epoch is 758 / 1000\n",
      "Loss is -141.11219787597656\n",
      "Epoch is 759 / 1000\n",
      "Loss is -175.95999145507812\n",
      "Epoch is 760 / 1000\n",
      "Loss is -135.71807861328125\n",
      "Epoch is 761 / 1000\n",
      "Loss is -148.1200714111328\n",
      "Epoch is 762 / 1000\n",
      "Loss is -192.0857391357422\n",
      "Epoch is 763 / 1000\n",
      "Loss is -139.3408203125\n",
      "Epoch is 764 / 1000\n",
      "Loss is -153.54000854492188\n",
      "Epoch is 765 / 1000\n",
      "Loss is -200.14842224121094\n",
      "Epoch is 766 / 1000\n",
      "Loss is -178.33030700683594\n",
      "Epoch is 767 / 1000\n",
      "Loss is -141.42462158203125\n",
      "Epoch is 768 / 1000\n",
      "Loss is -138.44102478027344\n",
      "Epoch is 769 / 1000\n",
      "Loss is -129.70848083496094\n",
      "Epoch is 770 / 1000\n",
      "Loss is -214.89869689941406\n",
      "Epoch is 771 / 1000\n",
      "Loss is -176.2803955078125\n",
      "Epoch is 772 / 1000\n",
      "Loss is -97.74591827392578\n",
      "Epoch is 773 / 1000\n",
      "Loss is -162.202392578125\n",
      "Epoch is 774 / 1000\n",
      "Loss is -105.7060546875\n",
      "Epoch is 775 / 1000\n",
      "Loss is -186.37881469726562\n",
      "Epoch is 776 / 1000\n",
      "Loss is -165.8807373046875\n",
      "Epoch is 777 / 1000\n",
      "Loss is -155.3607177734375\n",
      "Epoch is 778 / 1000\n",
      "Loss is -219.37136840820312\n",
      "Epoch is 779 / 1000\n",
      "Loss is -140.47853088378906\n",
      "Epoch is 780 / 1000\n",
      "Loss is -152.84027099609375\n",
      "Epoch is 781 / 1000\n",
      "Loss is -187.2133026123047\n",
      "Epoch is 782 / 1000\n",
      "Loss is -132.66375732421875\n",
      "Epoch is 783 / 1000\n",
      "Loss is -153.9488525390625\n",
      "Epoch is 784 / 1000\n",
      "Loss is -181.672119140625\n",
      "Epoch is 785 / 1000\n",
      "Loss is -160.22650146484375\n",
      "Epoch is 786 / 1000\n",
      "Loss is -176.77076721191406\n",
      "Epoch is 787 / 1000\n",
      "Loss is -155.9539337158203\n",
      "Epoch is 788 / 1000\n",
      "Loss is -144.4132843017578\n",
      "Epoch is 789 / 1000\n",
      "Loss is -169.1277618408203\n",
      "Epoch is 790 / 1000\n",
      "Loss is -153.191650390625\n",
      "Epoch is 791 / 1000\n",
      "Loss is -166.7845916748047\n",
      "Epoch is 792 / 1000\n",
      "Loss is -189.6131591796875\n",
      "Epoch is 793 / 1000\n",
      "Loss is -186.087646484375\n",
      "Epoch is 794 / 1000\n",
      "Loss is -157.4586639404297\n",
      "Epoch is 795 / 1000\n",
      "Loss is -172.30740356445312\n",
      "Epoch is 796 / 1000\n",
      "Loss is -145.08055114746094\n",
      "Epoch is 797 / 1000\n",
      "Loss is -162.6837615966797\n",
      "Epoch is 798 / 1000\n",
      "Loss is -135.12579345703125\n",
      "Epoch is 799 / 1000\n",
      "Loss is -165.50762939453125\n",
      "Epoch is 800 / 1000\n",
      "Loss is -137.64010620117188\n",
      "Epoch is 801 / 1000\n",
      "Loss is -160.003173828125\n",
      "Epoch is 802 / 1000\n",
      "Loss is -187.05198669433594\n",
      "Epoch is 803 / 1000\n",
      "Loss is -167.49815368652344\n",
      "Epoch is 804 / 1000\n",
      "Loss is -191.6526336669922\n",
      "Epoch is 805 / 1000\n",
      "Loss is -134.79986572265625\n",
      "Epoch is 806 / 1000\n",
      "Loss is -175.84353637695312\n",
      "Epoch is 807 / 1000\n",
      "Loss is -179.55923461914062\n",
      "Epoch is 808 / 1000\n",
      "Loss is -187.62295532226562\n",
      "Epoch is 809 / 1000\n",
      "Loss is -107.77320861816406\n",
      "Epoch is 810 / 1000\n",
      "Loss is -150.78353881835938\n",
      "Epoch is 811 / 1000\n",
      "Loss is -199.8751220703125\n",
      "Epoch is 812 / 1000\n",
      "Loss is -148.75555419921875\n",
      "Epoch is 813 / 1000\n",
      "Loss is -165.5015869140625\n",
      "Epoch is 814 / 1000\n",
      "Loss is -201.99290466308594\n",
      "Epoch is 815 / 1000\n",
      "Loss is -149.90899658203125\n",
      "Epoch is 816 / 1000\n",
      "Loss is -152.44154357910156\n",
      "Epoch is 817 / 1000\n",
      "Loss is -190.6576690673828\n",
      "Epoch is 818 / 1000\n",
      "Loss is -211.45826721191406\n",
      "Epoch is 819 / 1000\n",
      "Loss is -183.75343322753906\n",
      "Epoch is 820 / 1000\n",
      "Loss is -170.006103515625\n",
      "Epoch is 821 / 1000\n",
      "Loss is -181.1066436767578\n",
      "Epoch is 822 / 1000\n",
      "Loss is -147.96484375\n",
      "Epoch is 823 / 1000\n",
      "Loss is -157.95567321777344\n",
      "Epoch is 824 / 1000\n",
      "Loss is -179.39100646972656\n",
      "Epoch is 825 / 1000\n",
      "Loss is -123.79547119140625\n",
      "Epoch is 826 / 1000\n",
      "Loss is -185.3740997314453\n",
      "Epoch is 827 / 1000\n",
      "Loss is -202.3690185546875\n",
      "Epoch is 828 / 1000\n",
      "Loss is -169.36849975585938\n",
      "Epoch is 829 / 1000\n",
      "Loss is -210.04144287109375\n",
      "Epoch is 830 / 1000\n",
      "Loss is -139.05352783203125\n",
      "Epoch is 831 / 1000\n",
      "Loss is -196.26283264160156\n",
      "Epoch is 832 / 1000\n",
      "Loss is -163.42913818359375\n",
      "Epoch is 833 / 1000\n",
      "Loss is -192.40707397460938\n",
      "Epoch is 834 / 1000\n",
      "Loss is -178.4444122314453\n",
      "Epoch is 835 / 1000\n",
      "Loss is -170.28427124023438\n",
      "Epoch is 836 / 1000\n",
      "Loss is -182.62295532226562\n",
      "Epoch is 837 / 1000\n",
      "Loss is -162.5302734375\n",
      "Epoch is 838 / 1000\n",
      "Loss is -154.29998779296875\n",
      "Epoch is 839 / 1000\n",
      "Loss is -191.06646728515625\n",
      "Epoch is 840 / 1000\n",
      "Loss is -145.833251953125\n",
      "Epoch is 841 / 1000\n",
      "Loss is -217.98255920410156\n",
      "Epoch is 842 / 1000\n",
      "Loss is -178.552978515625\n",
      "Epoch is 843 / 1000\n",
      "Loss is -203.0994873046875\n",
      "Epoch is 844 / 1000\n",
      "Loss is -162.05747985839844\n",
      "Epoch is 845 / 1000\n",
      "Loss is -153.7744140625\n",
      "Epoch is 846 / 1000\n",
      "Loss is -154.29139709472656\n",
      "Epoch is 847 / 1000\n",
      "Loss is -153.3716278076172\n",
      "Epoch is 848 / 1000\n",
      "Loss is -158.53817749023438\n",
      "Epoch is 849 / 1000\n",
      "Loss is -150.117431640625\n",
      "Epoch is 850 / 1000\n",
      "Loss is -169.2070770263672\n",
      "Epoch is 851 / 1000\n",
      "Loss is -163.9371795654297\n",
      "Epoch is 852 / 1000\n",
      "Loss is -120.0304183959961\n",
      "Epoch is 853 / 1000\n",
      "Loss is -208.41482543945312\n",
      "Epoch is 854 / 1000\n",
      "Loss is -175.05526733398438\n",
      "Epoch is 855 / 1000\n",
      "Loss is -139.24647521972656\n",
      "Epoch is 856 / 1000\n",
      "Loss is -202.80282592773438\n",
      "Epoch is 857 / 1000\n",
      "Loss is -148.51124572753906\n",
      "Epoch is 858 / 1000\n",
      "Loss is -153.7386932373047\n",
      "Epoch is 859 / 1000\n",
      "Loss is -199.84640502929688\n",
      "Epoch is 860 / 1000\n",
      "Loss is -182.42971801757812\n",
      "Epoch is 861 / 1000\n",
      "Loss is -115.62882995605469\n",
      "Epoch is 862 / 1000\n",
      "Loss is -167.1959991455078\n",
      "Epoch is 863 / 1000\n",
      "Loss is -113.27112579345703\n",
      "Epoch is 864 / 1000\n",
      "Loss is -181.68377685546875\n",
      "Epoch is 865 / 1000\n",
      "Loss is -180.9916229248047\n",
      "Epoch is 866 / 1000\n",
      "Loss is -144.64862060546875\n",
      "Epoch is 867 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is -169.90615844726562\n",
      "Epoch is 868 / 1000\n",
      "Loss is -179.82037353515625\n",
      "Epoch is 869 / 1000\n",
      "Loss is -205.82986450195312\n",
      "Epoch is 870 / 1000\n",
      "Loss is -201.5794219970703\n",
      "Epoch is 871 / 1000\n",
      "Loss is -177.5420684814453\n",
      "Epoch is 872 / 1000\n",
      "Loss is -179.31378173828125\n",
      "Epoch is 873 / 1000\n",
      "Loss is -151.90219116210938\n",
      "Epoch is 874 / 1000\n",
      "Loss is -172.15185546875\n",
      "Epoch is 875 / 1000\n",
      "Loss is -182.1660614013672\n",
      "Epoch is 876 / 1000\n",
      "Loss is -163.6988067626953\n",
      "Epoch is 877 / 1000\n",
      "Loss is -197.9488525390625\n",
      "Epoch is 878 / 1000\n",
      "Loss is -169.78704833984375\n",
      "Epoch is 879 / 1000\n",
      "Loss is -149.2339630126953\n",
      "Epoch is 880 / 1000\n",
      "Loss is -173.68212890625\n",
      "Epoch is 881 / 1000\n",
      "Loss is -178.85015869140625\n",
      "Epoch is 882 / 1000\n",
      "Loss is -173.86109924316406\n",
      "Epoch is 883 / 1000\n",
      "Loss is -207.51036071777344\n",
      "Epoch is 884 / 1000\n",
      "Loss is -175.89166259765625\n",
      "Epoch is 885 / 1000\n",
      "Loss is -233.87754821777344\n",
      "Epoch is 886 / 1000\n",
      "Loss is -163.35049438476562\n",
      "Epoch is 887 / 1000\n",
      "Loss is -167.76263427734375\n",
      "Epoch is 888 / 1000\n",
      "Loss is -144.9151153564453\n",
      "Epoch is 889 / 1000\n",
      "Loss is -153.59774780273438\n",
      "Epoch is 890 / 1000\n",
      "Loss is -214.01275634765625\n",
      "Epoch is 891 / 1000\n",
      "Loss is -167.60836791992188\n",
      "Epoch is 892 / 1000\n",
      "Loss is -173.59559631347656\n",
      "Epoch is 893 / 1000\n",
      "Loss is -191.36558532714844\n",
      "Epoch is 894 / 1000\n",
      "Loss is -179.44235229492188\n",
      "Epoch is 895 / 1000\n",
      "Loss is -160.91549682617188\n",
      "Epoch is 896 / 1000\n",
      "Loss is -138.54217529296875\n",
      "Epoch is 897 / 1000\n",
      "Loss is -193.84266662597656\n",
      "Epoch is 898 / 1000\n",
      "Loss is -172.6788330078125\n",
      "Epoch is 899 / 1000\n",
      "Loss is -188.1189727783203\n",
      "Epoch is 900 / 1000\n",
      "Loss is -149.475830078125\n",
      "Epoch is 901 / 1000\n",
      "Loss is -169.5455322265625\n",
      "Epoch is 902 / 1000\n",
      "Loss is -136.32131958007812\n",
      "Epoch is 903 / 1000\n",
      "Loss is -181.6973419189453\n",
      "Epoch is 904 / 1000\n",
      "Loss is -157.50587463378906\n",
      "Epoch is 905 / 1000\n",
      "Loss is -207.66065979003906\n",
      "Epoch is 906 / 1000\n",
      "Loss is -205.03836059570312\n",
      "Epoch is 907 / 1000\n",
      "Loss is -167.43954467773438\n",
      "Epoch is 908 / 1000\n",
      "Loss is -126.25545501708984\n",
      "Epoch is 909 / 1000\n",
      "Loss is -144.66665649414062\n",
      "Epoch is 910 / 1000\n",
      "Loss is -152.75515747070312\n",
      "Epoch is 911 / 1000\n",
      "Loss is -211.49124145507812\n",
      "Epoch is 912 / 1000\n",
      "Loss is -178.26461791992188\n",
      "Epoch is 913 / 1000\n",
      "Loss is -225.81536865234375\n",
      "Epoch is 914 / 1000\n",
      "Loss is -156.1248321533203\n",
      "Epoch is 915 / 1000\n",
      "Loss is -131.60696411132812\n",
      "Epoch is 916 / 1000\n",
      "Loss is -205.79116821289062\n",
      "Epoch is 917 / 1000\n",
      "Loss is -200.89962768554688\n",
      "Epoch is 918 / 1000\n",
      "Loss is -189.11724853515625\n",
      "Epoch is 919 / 1000\n",
      "Loss is -153.26800537109375\n",
      "Epoch is 920 / 1000\n",
      "Loss is -208.3943328857422\n",
      "Epoch is 921 / 1000\n",
      "Loss is -224.3778076171875\n",
      "Epoch is 922 / 1000\n",
      "Loss is -170.141845703125\n",
      "Epoch is 923 / 1000\n",
      "Loss is -197.23570251464844\n",
      "Epoch is 924 / 1000\n",
      "Loss is -159.76329040527344\n",
      "Epoch is 925 / 1000\n",
      "Loss is -136.7249755859375\n",
      "Epoch is 926 / 1000\n",
      "Loss is -206.85670471191406\n",
      "Epoch is 927 / 1000\n",
      "Loss is -167.13526916503906\n",
      "Epoch is 928 / 1000\n",
      "Loss is -164.88253784179688\n",
      "Epoch is 929 / 1000\n",
      "Loss is -154.30184936523438\n",
      "Epoch is 930 / 1000\n",
      "Loss is -209.11524963378906\n",
      "Epoch is 931 / 1000\n",
      "Loss is -187.7225341796875\n",
      "Epoch is 932 / 1000\n",
      "Loss is -192.36936950683594\n",
      "Epoch is 933 / 1000\n",
      "Loss is -159.66151428222656\n",
      "Epoch is 934 / 1000\n",
      "Loss is -173.61724853515625\n",
      "Epoch is 935 / 1000\n",
      "Loss is -173.59136962890625\n",
      "Epoch is 936 / 1000\n",
      "Loss is -140.90414428710938\n",
      "Epoch is 937 / 1000\n",
      "Loss is -164.60406494140625\n",
      "Epoch is 938 / 1000\n",
      "Loss is -187.78562927246094\n",
      "Epoch is 939 / 1000\n",
      "Loss is -191.93222045898438\n",
      "Epoch is 940 / 1000\n",
      "Loss is -162.25404357910156\n",
      "Epoch is 941 / 1000\n",
      "Loss is -183.70570373535156\n",
      "Epoch is 942 / 1000\n",
      "Loss is -173.3804931640625\n",
      "Epoch is 943 / 1000\n",
      "Loss is -181.1237030029297\n",
      "Epoch is 944 / 1000\n",
      "Loss is -191.82606506347656\n",
      "Epoch is 945 / 1000\n",
      "Loss is -151.29637145996094\n",
      "Epoch is 946 / 1000\n",
      "Loss is -196.64669799804688\n",
      "Epoch is 947 / 1000\n",
      "Loss is -218.75436401367188\n",
      "Epoch is 948 / 1000\n",
      "Loss is -170.0595703125\n",
      "Epoch is 949 / 1000\n",
      "Loss is -202.80838012695312\n",
      "Epoch is 950 / 1000\n",
      "Loss is -154.2647247314453\n",
      "Epoch is 951 / 1000\n",
      "Loss is -191.79843139648438\n",
      "Epoch is 952 / 1000\n",
      "Loss is -173.81817626953125\n",
      "Epoch is 953 / 1000\n",
      "Loss is -212.43548583984375\n",
      "Epoch is 954 / 1000\n",
      "Loss is -148.38194274902344\n",
      "Epoch is 955 / 1000\n",
      "Loss is -159.28073120117188\n",
      "Epoch is 956 / 1000\n",
      "Loss is -198.65887451171875\n",
      "Epoch is 957 / 1000\n",
      "Loss is -178.20278930664062\n",
      "Epoch is 958 / 1000\n",
      "Loss is -170.49554443359375\n",
      "Epoch is 959 / 1000\n",
      "Loss is -190.60348510742188\n",
      "Epoch is 960 / 1000\n",
      "Loss is -169.72479248046875\n",
      "Epoch is 961 / 1000\n",
      "Loss is -190.2193603515625\n",
      "Epoch is 962 / 1000\n",
      "Loss is -217.378173828125\n",
      "Epoch is 963 / 1000\n",
      "Loss is -163.8999481201172\n",
      "Epoch is 964 / 1000\n",
      "Loss is -180.8902130126953\n",
      "Epoch is 965 / 1000\n",
      "Loss is -169.8333282470703\n",
      "Epoch is 966 / 1000\n",
      "Loss is -196.87269592285156\n",
      "Epoch is 967 / 1000\n",
      "Loss is -184.92227172851562\n",
      "Epoch is 968 / 1000\n",
      "Loss is -206.03091430664062\n",
      "Epoch is 969 / 1000\n",
      "Loss is -183.5787353515625\n",
      "Epoch is 970 / 1000\n",
      "Loss is -227.252685546875\n",
      "Epoch is 971 / 1000\n",
      "Loss is -148.015625\n",
      "Epoch is 972 / 1000\n",
      "Loss is -188.8888702392578\n",
      "Epoch is 973 / 1000\n",
      "Loss is -221.29055786132812\n",
      "Epoch is 974 / 1000\n",
      "Loss is -190.0132293701172\n",
      "Epoch is 975 / 1000\n",
      "Loss is -151.20863342285156\n",
      "Epoch is 976 / 1000\n",
      "Loss is -197.7696533203125\n",
      "Epoch is 977 / 1000\n",
      "Loss is -165.61441040039062\n",
      "Epoch is 978 / 1000\n",
      "Loss is -140.56431579589844\n",
      "Epoch is 979 / 1000\n",
      "Loss is -259.4114074707031\n",
      "Epoch is 980 / 1000\n",
      "Loss is -208.68511962890625\n",
      "Epoch is 981 / 1000\n",
      "Loss is -188.76263427734375\n",
      "Epoch is 982 / 1000\n",
      "Loss is -171.8997039794922\n",
      "Epoch is 983 / 1000\n",
      "Loss is -175.2200164794922\n",
      "Epoch is 984 / 1000\n",
      "Loss is -174.87396240234375\n",
      "Epoch is 985 / 1000\n",
      "Loss is -175.6322479248047\n",
      "Epoch is 986 / 1000\n",
      "Loss is -179.95352172851562\n",
      "Epoch is 987 / 1000\n",
      "Loss is -172.44003295898438\n",
      "Epoch is 988 / 1000\n",
      "Loss is -147.3635711669922\n",
      "Epoch is 989 / 1000\n",
      "Loss is -170.09783935546875\n",
      "Epoch is 990 / 1000\n",
      "Loss is -173.66925048828125\n",
      "Epoch is 991 / 1000\n",
      "Loss is -196.33441162109375\n",
      "Epoch is 992 / 1000\n",
      "Loss is -146.9340057373047\n",
      "Epoch is 993 / 1000\n",
      "Loss is -155.63528442382812\n",
      "Epoch is 994 / 1000\n",
      "Loss is -196.1422882080078\n",
      "Epoch is 995 / 1000\n",
      "Loss is -167.08111572265625\n",
      "Epoch is 996 / 1000\n",
      "Loss is -190.06063842773438\n",
      "Epoch is 997 / 1000\n",
      "Loss is -174.1571502685547\n",
      "Epoch is 998 / 1000\n",
      "Loss is -212.74935913085938\n",
      "Epoch is 999 / 1000\n",
      "Loss is -207.21630859375\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    permutation = torch.randperm(batches)\n",
    "    print('Epoch is',i,'/',epochs)\n",
    "    opt.zero_grad()\n",
    "    s = model(itensor[permutation[0:minibatch_size]],ftensor[permutation[0:minibatch_size]])\n",
    "    c = loss(s.squeeze(),wrtensor[permutation[0:minibatch_size]])\n",
    "    print('Loss is',c.item())\n",
    "    c.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
